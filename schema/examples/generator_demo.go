package main

import (
	"fmt"
	"log"
	"os"

	"github.com/sjzsdu/langchaingo-cn/schema"
)

func main() {
	fmt.Println("ğŸš€ LangChainGo-CN é…ç½®æ–‡ä»¶ç”Ÿæˆå™¨æ¼”ç¤º")
	fmt.Println("=======================================")

	// åˆ›å»ºè¾“å‡ºç›®å½•
	outputDir := "generated_configs"
	if err := os.MkdirAll(outputDir, 0755); err != nil {
		log.Fatal("åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥:", err)
	}

	// åˆ›å»ºé…ç½®ç”Ÿæˆå™¨
	generator := schema.NewConfigGenerator(outputDir)

	// 1. ç”Ÿæˆæç®€LLMé…ç½®
	fmt.Println("\nğŸ“ ç”ŸæˆLLMé…ç½®æ–‡ä»¶...")
	err := generator.GenerateLLMConfig(schema.LLMTemplate{
		Type:        "deepseek",
		Model:       "deepseek-chat",
		Temperature: 0.7,
		MaxTokens:   2048,
	}, "deepseek_llm.json")
	if err != nil {
		log.Printf("ç”ŸæˆLLMé…ç½®å¤±è´¥: %v", err)
	}

	// 2. ç”ŸæˆChainé…ç½®
	fmt.Println("\nâ›“ï¸  ç”ŸæˆChainé…ç½®æ–‡ä»¶...")
	err = generator.GenerateChainConfig(schema.ChainTemplate{
		Type: "conversation",
		LLMTemplate: schema.LLMTemplate{
			Type:        "kimi",
			Model:       "moonshot-v1-8k",
			Temperature: 0.7,
		},
		MemoryType:     "conversation_buffer",
		PromptTemplate: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ï¼š{{.input}}",
		InputVariables: []string{"input"},
	}, "kimi_chat_chain.json")
	if err != nil {
		log.Printf("ç”ŸæˆChainé…ç½®å¤±è´¥: %v", err)
	}

	// 3. ç”ŸæˆAgenté…ç½®
	fmt.Println("\nğŸ¤– ç”ŸæˆAgenté…ç½®æ–‡ä»¶...")
	err = generator.GenerateAgentConfig(schema.AgentTemplate{
		Type: "zero_shot_react",
		LLMTemplate: schema.LLMTemplate{
			Type:        "openai",
			Model:       "gpt-4",
			Temperature: 0.3,
			MaxTokens:   2048,
		},
		MemoryType: "conversation_buffer",
		MaxSteps:   5,
	}, "openai_agent.json")
	if err != nil {
		log.Printf("ç”ŸæˆAgenté…ç½®å¤±è´¥: %v", err)
	}

	// 4. ç”ŸæˆExecutoré…ç½®ï¼ˆæ–°é£æ ¼ï¼‰
	fmt.Println("\nâš¡ ç”ŸæˆExecutoré…ç½®æ–‡ä»¶...")
	err = generator.GenerateExecutorConfig(schema.ExecutorTemplate{
		AgentTemplate: schema.AgentTemplate{
			Type: "conversational_react",
			LLMTemplate: schema.LLMTemplate{
				Type:        "qwen",
				Model:       "qwen-plus",
				Temperature: 0.5,
				MaxTokens:   1500,
			},
			MemoryType: "conversation_buffer",
			MaxSteps:   3,
		},
		MaxIterations:           8,
		ReturnIntermediateSteps: true,
	}, "qwen_executor.json")
	if err != nil {
		log.Printf("ç”ŸæˆExecutoré…ç½®å¤±è´¥: %v", err)
	}

	// 5. ä½¿ç”¨å¿«æ·æ–¹æ³•ç”Ÿæˆå¸¸ç”¨é…ç½®
	fmt.Println("\nğŸ”¥ ç”Ÿæˆå¸¸ç”¨é¢„è®¾é…ç½®...")

	// DeepSeekèŠå¤©é…ç½®
	err = generator.GenerateDeepSeekChatConfig("deepseek_chat.json")
	if err != nil {
		log.Printf("ç”ŸæˆDeepSeekèŠå¤©é…ç½®å¤±è´¥: %v", err)
	}

	// KimièŠå¤©é…ç½®
	err = generator.GenerateKimiChatConfig("kimi_chat.json")
	if err != nil {
		log.Printf("ç”ŸæˆKimièŠå¤©é…ç½®å¤±è´¥: %v", err)
	}

	// OpenAIèŠå¤©é…ç½®
	err = generator.GenerateOpenAIChatConfig("openai_chat.json")
	if err != nil {
		log.Printf("ç”ŸæˆOpenAIèŠå¤©é…ç½®å¤±è´¥: %v", err)
	}

	// ReActæ™ºèƒ½ä½“é…ç½®
	err = generator.GenerateReactAgentConfig("deepseek", "deepseek-chat", "deepseek_react_agent.json")
	if err != nil {
		log.Printf("ç”ŸæˆReActæ™ºèƒ½ä½“é…ç½®å¤±è´¥: %v", err)
	}

	// å¯¹è¯æ™ºèƒ½ä½“é…ç½®
	err = generator.GenerateConversationalAgentConfig("kimi", "moonshot-v1-8k", "kimi_conversational_agent.json")
	if err != nil {
		log.Printf("ç”Ÿæˆå¯¹è¯æ™ºèƒ½ä½“é…ç½®å¤±è´¥: %v", err)
	}

	// DeepSeekæ‰§è¡Œå™¨é…ç½®
	err = generator.GenerateExecutorWithDeepSeek("deepseek_executor.json")
	if err != nil {
		log.Printf("ç”ŸæˆDeepSeekæ‰§è¡Œå™¨é…ç½®å¤±è´¥: %v", err)
	}

	// 6. ä½¿ç”¨å…¨å±€é—¨é¢æ–¹æ³•ï¼ˆæœ€ç®€å•çš„æ–¹å¼ï¼‰
	fmt.Println("\nâš¡ ä½¿ç”¨å…¨å±€é—¨é¢æ–¹æ³•ç”Ÿæˆé…ç½®...")

	// å¿«é€Ÿç”ŸæˆLLMé…ç½®
	err = schema.QuickGenerateLLM("anthropic", "claude-3-sonnet-20240229", "quick_anthropic.json")
	if err != nil {
		log.Printf("å¿«é€Ÿç”ŸæˆAnthropicé…ç½®å¤±è´¥: %v", err)
	}

	// å¿«é€Ÿç”ŸæˆChainé…ç½®
	err = schema.QuickGenerateChain("llm", "ollama", "llama2", "quick_ollama_chain.json")
	if err != nil {
		log.Printf("å¿«é€Ÿç”ŸæˆOllama Chainé…ç½®å¤±è´¥: %v", err)
	}

	// å¿«é€Ÿç”ŸæˆAgenté…ç½®
	err = schema.QuickGenerateAgent("zero_shot_react", "deepseek", "deepseek-chat", "quick_agent.json")
	if err != nil {
		log.Printf("å¿«é€Ÿç”ŸæˆAgenté…ç½®å¤±è´¥: %v", err)
	}

	// å¿«é€Ÿç”ŸæˆExecutoré…ç½®
	err = schema.QuickGenerateExecutor("conversational_react", "kimi", "moonshot-v1-8k", "quick_executor.json")
	if err != nil {
		log.Printf("å¿«é€Ÿç”ŸæˆExecutoré…ç½®å¤±è´¥: %v", err)
	}

	fmt.Println("\nâœ¨ é…ç½®æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
	fmt.Printf("ğŸ“ æ‰€æœ‰é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°ç›®å½•: %s\n", outputDir)
	fmt.Println("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
	fmt.Println("   1. è®¾ç½®ç›¸åº”çš„ç¯å¢ƒå˜é‡ï¼ˆå¦‚ DEEPSEEK_API_KEYã€KIMI_API_KEY ç­‰ï¼‰")
	fmt.Println("   2. ä½¿ç”¨ schema.CreateApplicationFromFile() åŠ è½½é…ç½®")
	fmt.Println("   3. å¼€å§‹ä½¿ç”¨ç”Ÿæˆçš„ç»„ä»¶ï¼")

	fmt.Println("\nğŸ“‹ ç”Ÿæˆçš„é…ç½®æ–‡ä»¶åˆ—è¡¨:")
	files := []string{
		"deepseek_llm.json",
		"kimi_chat_chain.json",
		"openai_agent.json",
		"qwen_executor.json",
		"deepseek_chat.json",
		"kimi_chat.json",
		"openai_chat.json",
		"deepseek_react_agent.json",
		"kimi_conversational_agent.json",
		"deepseek_executor.json",
		"quick_anthropic.json",
		"quick_ollama_chain.json",
		"quick_agent.json",
		"quick_executor.json",
	}

	for i, file := range files {
		fmt.Printf("   %2d. %s\n", i+1, file)
	}
}
