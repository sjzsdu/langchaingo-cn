package cmd

import (
	"fmt"
	"log"
	"strings"

	"github.com/sjzsdu/langchaingo-cn/schema"
	"github.com/spf13/cobra"
)

var (
	// å…¨å±€é…ç½®
	outputDir  string
	outputFile string
	verbose    bool

	// LLMé…ç½®
	llmType     string
	model       string
	temperature float64
	maxTokens   int
	baseURL     string

	// Chainé…ç½®
	chainType      string
	memoryType     string
	promptTemplate string

	// Agenté…ç½®
	agentType string
	maxSteps  int

	// Executoré…ç½®
	maxIterations           int
	returnIntermediateSteps bool
)

var configGenCmd = &cobra.Command{
	Use:   "config-gen",
	Short: "ğŸš€ LangChainGo-CN é…ç½®æ–‡ä»¶ç”Ÿæˆå™¨",
	Long: `ğŸš€ LangChainGo-CN é…ç½®æ–‡ä»¶ç”Ÿæˆå™¨

ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿç”ŸæˆLangChainç»„ä»¶é…ç½®æ–‡ä»¶ã€‚
æ”¯æŒLLMã€Chainã€Agentã€Executorç­‰ç»„ä»¶çš„é…ç½®ç”Ÿæˆã€‚

æ”¯æŒçš„LLMç±»å‹:
  â€¢ deepseek    - DeepSeekæ¨¡å‹
  â€¢ kimi        - Kimiæœˆä¹‹æš—é¢æ¨¡å‹
  â€¢ openai      - OpenAI GPTæ¨¡å‹
  â€¢ qwen        - é€šä¹‰åƒé—®æ¨¡å‹
  â€¢ anthropic   - Anthropic Claudeæ¨¡å‹
  â€¢ ollama      - æœ¬åœ°Ollamaæ¨¡å‹`,
	Example: `  # ç”ŸæˆDeepSeekèŠå¤©é…ç½®
  langchaingo-cn config-gen preset deepseek-chat -o deepseek.json

  # ç”Ÿæˆè‡ªå®šä¹‰LLMé…ç½®
  langchaingo-cn config-gen llm --llm deepseek --model deepseek-chat -o my_llm.json

  # ç”ŸæˆChainé…ç½®
  langchaingo-cn config-gen chain --llm kimi --model moonshot-v1-8k --memory conversation_buffer

  # ç”ŸæˆAgenté…ç½®
  langchaingo-cn config-gen agent --llm openai --model gpt-4 --agent-type zero_shot_react`,
}

// LLMå‘½ä»¤
var llmCmd = &cobra.Command{
	Use:   "llm",
	Short: "ç”ŸæˆLLMé…ç½®æ–‡ä»¶",
	Long:  "ç”Ÿæˆå¤§è¯­è¨€æ¨¡å‹(LLM)çš„é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒDeepSeekã€Kimiã€OpenAIç­‰æ¨¡å‹",
	Example: `  # ç”ŸæˆDeepSeeké…ç½®
  config-gen llm --llm deepseek --model deepseek-chat

  # ç”Ÿæˆå¸¦å‚æ•°çš„OpenAIé…ç½®
  config-gen llm --llm openai --model gpt-4 --temperature 0.7 --max-tokens 2048`,
	Run: func(cmd *cobra.Command, args []string) {
		if llmType == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šLLMç±»å‹ (--llm)")
		}
		if model == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šæ¨¡å‹åç§° (--model)")
		}

		generator := schema.NewConfigGenerator(outputDir)
		template := schema.LLMTemplate{
			Type:  llmType,
			Model: model,
		}

		if temperature > 0 {
			template.Temperature = temperature
		}
		if maxTokens > 0 {
			template.MaxTokens = maxTokens
		}
		if baseURL != "" {
			template.BaseURL = baseURL
		}

		if err := generator.GenerateLLMConfig(template, outputFile); err != nil {
			log.Fatal("âŒ ç”ŸæˆLLMé…ç½®å¤±è´¥:", err)
		}

		printSuccess("LLMé…ç½®")
	},
}

// Chainå‘½ä»¤
var chainCmd = &cobra.Command{
	Use:   "chain",
	Short: "ç”ŸæˆChainé…ç½®æ–‡ä»¶",
	Long:  "ç”Ÿæˆé“¾(Chain)çš„é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒå¯¹è¯é“¾ã€LLMé“¾ç­‰ç±»å‹",
	Example: `  # ç”Ÿæˆå¯¹è¯é“¾é…ç½®
  config-gen chain --llm deepseek --model deepseek-chat --memory conversation_buffer

  # ç”Ÿæˆå¸¦è‡ªå®šä¹‰æç¤ºçš„é“¾é…ç½®
  config-gen chain --llm kimi --model moonshot-v1-8k --prompt "ä½ æ˜¯ä¸“ä¸šåŠ©æ‰‹ï¼š{{.input}}"`,
	Run: func(cmd *cobra.Command, args []string) {
		if llmType == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šLLMç±»å‹ (--llm)")
		}
		if model == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šæ¨¡å‹åç§° (--model)")
		}

		generator := schema.NewConfigGenerator(outputDir)
		template := schema.ChainTemplate{
			Type: getChainType(),
			LLMTemplate: schema.LLMTemplate{
				Type:        llmType,
				Model:       model,
				Temperature: temperature,
			},
		}

		if maxTokens > 0 {
			template.LLMTemplate.MaxTokens = maxTokens
		}
		if baseURL != "" {
			template.LLMTemplate.BaseURL = baseURL
		}
		if memoryType != "" {
			template.MemoryType = memoryType
		}
		if promptTemplate != "" {
			template.PromptTemplate = promptTemplate
			template.InputVariables = []string{"input"}
		}

		if err := generator.GenerateChainConfig(template, outputFile); err != nil {
			log.Fatal("âŒ ç”ŸæˆChainé…ç½®å¤±è´¥:", err)
		}

		printSuccess("Chainé…ç½®")
	},
}

// Agentå‘½ä»¤
var agentCmd = &cobra.Command{
	Use:   "agent",
	Short: "ç”ŸæˆAgenté…ç½®æ–‡ä»¶",
	Long:  "ç”Ÿæˆæ™ºèƒ½ä½“(Agent)çš„é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒé›¶æ ·æœ¬ReActã€å¯¹è¯ReActç­‰ç±»å‹",
	Example: `  # ç”Ÿæˆé›¶æ ·æœ¬ReActæ™ºèƒ½ä½“
  config-gen agent --llm openai --model gpt-4 --agent-type zero_shot_react

  # ç”Ÿæˆå¯¹è¯æ™ºèƒ½ä½“
  config-gen agent --llm deepseek --model deepseek-chat --agent-type conversational_react --max-steps 5`,
	Run: func(cmd *cobra.Command, args []string) {
		if llmType == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šLLMç±»å‹ (--llm)")
		}
		if model == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šæ¨¡å‹åç§° (--model)")
		}

		generator := schema.NewConfigGenerator(outputDir)
		template := schema.AgentTemplate{
			Type: getAgentType(),
			LLMTemplate: schema.LLMTemplate{
				Type:        llmType,
				Model:       model,
				Temperature: temperature,
			},
			MemoryType: memoryType,
			MaxSteps:   maxSteps,
		}

		if maxTokens > 0 {
			template.LLMTemplate.MaxTokens = maxTokens
		}
		if baseURL != "" {
			template.LLMTemplate.BaseURL = baseURL
		}

		if err := generator.GenerateAgentConfig(template, outputFile); err != nil {
			log.Fatal("âŒ ç”ŸæˆAgenté…ç½®å¤±è´¥:", err)
		}

		printSuccess("Agenté…ç½®")
	},
}

// Executorå‘½ä»¤
var executorCmd = &cobra.Command{
	Use:   "executor",
	Short: "ç”ŸæˆExecutoré…ç½®æ–‡ä»¶",
	Long:  "ç”Ÿæˆæ‰§è¡Œå™¨(Executor)çš„é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨æ–°çš„usageé£æ ¼é…ç½®",
	Example: `  # ç”ŸæˆåŸºæœ¬æ‰§è¡Œå™¨é…ç½®
  config-gen executor --llm deepseek --model deepseek-chat

  # ç”Ÿæˆå¸¦è¯¦ç»†å‚æ•°çš„æ‰§è¡Œå™¨é…ç½®
  config-gen executor --llm kimi --model moonshot-v1-8k --max-iterations 10 --return-steps`,
	Run: func(cmd *cobra.Command, args []string) {
		if llmType == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šLLMç±»å‹ (--llm)")
		}
		if model == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šæ¨¡å‹åç§° (--model)")
		}

		generator := schema.NewConfigGenerator(outputDir)
		template := schema.ExecutorTemplate{
			AgentTemplate: schema.AgentTemplate{
				Type: getAgentType(),
				LLMTemplate: schema.LLMTemplate{
					Type:        llmType,
					Model:       model,
					Temperature: temperature,
				},
				MemoryType: memoryType,
				MaxSteps:   maxSteps,
			},
			MaxIterations:           maxIterations,
			ReturnIntermediateSteps: returnIntermediateSteps,
		}

		if maxTokens > 0 {
			template.AgentTemplate.LLMTemplate.MaxTokens = maxTokens
		}
		if baseURL != "" {
			template.AgentTemplate.LLMTemplate.BaseURL = baseURL
		}

		if err := generator.GenerateExecutorConfig(template, outputFile); err != nil {
			log.Fatal("âŒ ç”ŸæˆExecutoré…ç½®å¤±è´¥:", err)
		}

		printSuccess("Executoré…ç½®")
	},
}

// Presetå‘½ä»¤
var presetCmd = &cobra.Command{
	Use:       "preset [é…ç½®åç§°]",
	Short:     "ç”Ÿæˆé¢„è®¾é…ç½®æ–‡ä»¶",
	Long:      "ä½¿ç”¨é¢„å®šä¹‰çš„é…ç½®æ¨¡æ¿å¿«é€Ÿç”Ÿæˆå¸¸ç”¨é…ç½®æ–‡ä»¶",
	Args:      cobra.ExactArgs(1),
	ValidArgs: []string{"deepseek-chat", "kimi-chat", "openai-chat", "qwen-chat", "deepseek-executor"},
	Example: `  # ç”ŸæˆDeepSeekèŠå¤©é…ç½®
  config-gen preset deepseek-chat -o deepseek.json

  # ç”ŸæˆKimièŠå¤©é…ç½®
  config-gen preset kimi-chat -o kimi.json

  # ç”ŸæˆDeepSeekæ‰§è¡Œå™¨é…ç½®
  config-gen preset deepseek-executor -o executor.json`,
	Run: func(cmd *cobra.Command, args []string) {
		preset := args[0]
		generator := schema.NewConfigGenerator(outputDir)

		if err := generatePreset(generator, preset, outputFile); err != nil {
			log.Fatal("âŒ ç”Ÿæˆé¢„è®¾é…ç½®å¤±è´¥:", err)
		}

		printSuccess(fmt.Sprintf("é¢„è®¾é…ç½® [%s]", preset))
	},
}

// Listå‘½ä»¤
var listCmd = &cobra.Command{
	Use:   "list",
	Short: "åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„é¢„è®¾é…ç½®å’Œæ”¯æŒçš„ç±»å‹",
	Long:  "æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„é¢„è®¾é…ç½®ã€æ”¯æŒçš„LLMç±»å‹ã€Chainç±»å‹ç­‰ä¿¡æ¯",
	Run: func(cmd *cobra.Command, args []string) {
		fmt.Println("ğŸ“‹ å¯ç”¨çš„é¢„è®¾é…ç½®:")
		fmt.Println("  â€¢ deepseek-chat     - DeepSeekèŠå¤©é…ç½®")
		fmt.Println("  â€¢ kimi-chat         - KimièŠå¤©é…ç½®")
		fmt.Println("  â€¢ openai-chat       - OpenAIèŠå¤©é…ç½®")
		fmt.Println("  â€¢ qwen-chat         - é€šä¹‰åƒé—®èŠå¤©é…ç½®")
		fmt.Println("  â€¢ deepseek-executor - DeepSeekæ‰§è¡Œå™¨é…ç½®")

		fmt.Println("\nğŸ¤– æ”¯æŒçš„LLMç±»å‹:")
		fmt.Println("  â€¢ deepseek    - DeepSeekæ¨¡å‹")
		fmt.Println("  â€¢ kimi        - Kimiæœˆä¹‹æš—é¢æ¨¡å‹")
		fmt.Println("  â€¢ openai      - OpenAI GPTæ¨¡å‹")
		fmt.Println("  â€¢ qwen        - é€šä¹‰åƒé—®æ¨¡å‹")
		fmt.Println("  â€¢ anthropic   - Anthropic Claudeæ¨¡å‹")
		fmt.Println("  â€¢ ollama      - æœ¬åœ°Ollamaæ¨¡å‹")

		fmt.Println("\nâ›“ï¸  æ”¯æŒçš„Chainç±»å‹:")
		fmt.Println("  â€¢ conversation - å¯¹è¯é“¾")
		fmt.Println("  â€¢ llm          - LLMé“¾")
		fmt.Println("  â€¢ sequential   - é¡ºåºé“¾")

		fmt.Println("\nğŸ¤– æ”¯æŒçš„Agentç±»å‹:")
		fmt.Println("  â€¢ zero_shot_react      - é›¶æ ·æœ¬ReActæ™ºèƒ½ä½“")
		fmt.Println("  â€¢ conversational_react - å¯¹è¯ReActæ™ºèƒ½ä½“")

		fmt.Println("\nğŸ’¾ æ”¯æŒçš„Memoryç±»å‹:")
		fmt.Println("  â€¢ conversation_buffer - ä¼šè¯ç¼“å†²è®°å¿†")
		fmt.Println("  â€¢ simple              - ç®€å•è®°å¿†")
	},
}

func init() {
	// å…¨å±€æ ‡å¿—
	configGenCmd.PersistentFlags().StringVarP(&outputDir, "dir", "d", ".", "è¾“å‡ºç›®å½•")
	configGenCmd.PersistentFlags().StringVarP(&outputFile, "output", "o", "config.json", "è¾“å‡ºæ–‡ä»¶å")
	configGenCmd.PersistentFlags().BoolVarP(&verbose, "verbose", "v", false, "è¯¦ç»†è¾“å‡º")

	// LLMå‘½ä»¤æ ‡å¿—
	llmCmd.Flags().StringVar(&llmType, "llm", "", "LLMç±»å‹ (deepseek|kimi|openai|qwen|anthropic|ollama) [å¿…éœ€]")
	llmCmd.Flags().StringVar(&model, "model", "", "æ¨¡å‹åç§° [å¿…éœ€]")
	llmCmd.Flags().Float64Var(&temperature, "temperature", 0, "æ¸©åº¦å‚æ•° (0.0-2.0)")
	llmCmd.Flags().IntVar(&maxTokens, "max-tokens", 0, "æœ€å¤§tokenæ•°")
	llmCmd.Flags().StringVar(&baseURL, "base-url", "", "è‡ªå®šä¹‰APIåŸºç¡€URL")
	llmCmd.MarkFlagRequired("llm")
	llmCmd.MarkFlagRequired("model")

	// Chainå‘½ä»¤æ ‡å¿—
	chainCmd.Flags().StringVar(&llmType, "llm", "", "LLMç±»å‹ [å¿…éœ€]")
	chainCmd.Flags().StringVar(&model, "model", "", "æ¨¡å‹åç§° [å¿…éœ€]")
	chainCmd.Flags().StringVar(&chainType, "chain-type", "conversation", "Chainç±»å‹ (conversation|llm|sequential)")
	chainCmd.Flags().StringVar(&memoryType, "memory", "conversation_buffer", "Memoryç±»å‹ (conversation_buffer|simple)")
	chainCmd.Flags().StringVar(&promptTemplate, "prompt", "", "è‡ªå®šä¹‰æç¤ºæ¨¡æ¿")
	chainCmd.Flags().Float64Var(&temperature, "temperature", 0.7, "æ¸©åº¦å‚æ•°")
	chainCmd.Flags().IntVar(&maxTokens, "max-tokens", 0, "æœ€å¤§tokenæ•°")
	chainCmd.Flags().StringVar(&baseURL, "base-url", "", "è‡ªå®šä¹‰APIåŸºç¡€URL")
	chainCmd.MarkFlagRequired("llm")
	chainCmd.MarkFlagRequired("model")

	// Agentå‘½ä»¤æ ‡å¿—
	agentCmd.Flags().StringVar(&llmType, "llm", "", "LLMç±»å‹ [å¿…éœ€]")
	agentCmd.Flags().StringVar(&model, "model", "", "æ¨¡å‹åç§° [å¿…éœ€]")
	agentCmd.Flags().StringVar(&agentType, "agent-type", "zero_shot_react", "Agentç±»å‹ (zero_shot_react|conversational_react)")
	agentCmd.Flags().StringVar(&memoryType, "memory", "conversation_buffer", "Memoryç±»å‹")
	agentCmd.Flags().IntVar(&maxSteps, "max-steps", 5, "æœ€å¤§æ­¥æ•°")
	agentCmd.Flags().Float64Var(&temperature, "temperature", 0.3, "æ¸©åº¦å‚æ•°")
	agentCmd.Flags().IntVar(&maxTokens, "max-tokens", 0, "æœ€å¤§tokenæ•°")
	agentCmd.Flags().StringVar(&baseURL, "base-url", "", "è‡ªå®šä¹‰APIåŸºç¡€URL")
	agentCmd.MarkFlagRequired("llm")
	agentCmd.MarkFlagRequired("model")

	// Executorå‘½ä»¤æ ‡å¿—
	executorCmd.Flags().StringVar(&llmType, "llm", "", "LLMç±»å‹ [å¿…éœ€]")
	executorCmd.Flags().StringVar(&model, "model", "", "æ¨¡å‹åç§° [å¿…éœ€]")
	executorCmd.Flags().StringVar(&agentType, "agent-type", "zero_shot_react", "Agentç±»å‹")
	executorCmd.Flags().StringVar(&memoryType, "memory", "conversation_buffer", "Memoryç±»å‹")
	executorCmd.Flags().IntVar(&maxSteps, "max-steps", 5, "æœ€å¤§æ­¥æ•°")
	executorCmd.Flags().IntVar(&maxIterations, "max-iterations", 10, "æœ€å¤§è¿­ä»£æ¬¡æ•°")
	executorCmd.Flags().BoolVar(&returnIntermediateSteps, "return-steps", false, "è¿”å›ä¸­é—´æ­¥éª¤")
	executorCmd.Flags().Float64Var(&temperature, "temperature", 0.7, "æ¸©åº¦å‚æ•°")
	executorCmd.Flags().IntVar(&maxTokens, "max-tokens", 0, "æœ€å¤§tokenæ•°")
	executorCmd.Flags().StringVar(&baseURL, "base-url", "", "è‡ªå®šä¹‰APIåŸºç¡€URL")
	executorCmd.MarkFlagRequired("llm")
	executorCmd.MarkFlagRequired("model")

	// æ·»åŠ å­å‘½ä»¤
	configGenCmd.AddCommand(llmCmd)
	configGenCmd.AddCommand(chainCmd)
	configGenCmd.AddCommand(agentCmd)
	configGenCmd.AddCommand(executorCmd)
	configGenCmd.AddCommand(presetCmd)
	configGenCmd.AddCommand(listCmd)
}

// è¾…åŠ©å‡½æ•°
func getChainType() string {
	if chainType == "" {
		return "conversation"
	}
	return chainType
}

func getAgentType() string {
	if agentType == "" {
		return "zero_shot_react"
	}
	return agentType
}

func generatePreset(generator *schema.ConfigGenerator, preset, output string) error {
	switch strings.ToLower(preset) {
	case "deepseek-chat":
		return generator.GenerateDeepSeekChatConfig(output)
	case "kimi-chat":
		return generator.GenerateKimiChatConfig(output)
	case "openai-chat":
		return generator.GenerateOpenAIChatConfig(output)
	case "qwen-chat":
		return generator.GenerateQwenChatConfig(output)
	case "deepseek-executor":
		return generator.GenerateExecutorWithDeepSeek(output)
	default:
		return fmt.Errorf("ä¸æ”¯æŒçš„é¢„è®¾é…ç½®: %s", preset)
	}
}

func printSuccess(configType string) {
	if verbose {
		fmt.Printf("\nâœ¨ %sç”ŸæˆæˆåŠŸ!\n", configType)
		fmt.Printf("ğŸ“ æ–‡ä»¶ä½ç½®: %s/%s\n", outputDir, outputFile)
		fmt.Println("\nğŸ’¡ ä½¿ç”¨æŒ‡å—:")
		fmt.Println("   1. ğŸ”‘ è®¾ç½®ç›¸åº”çš„ç¯å¢ƒå˜é‡ (å¦‚ DEEPSEEK_API_KEY)")
		fmt.Println("   2. ğŸ“ ä½¿ç”¨ schema.CreateApplicationFromFile() åŠ è½½é…ç½®")
		fmt.Println("   3. ğŸš€ å¼€å§‹ä½¿ç”¨æ‚¨çš„AIåº”ç”¨!")
	} else {
		fmt.Printf("âœ… %så·²ç”Ÿæˆ: %s/%s\n", configType, outputDir, outputFile)
	}
}
