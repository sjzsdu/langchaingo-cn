package cmd

import (
	"context"
	"fmt"
	"log"
	"os"
	"strings"
	"time"

	"github.com/sjzsdu/langchaingo-cn/schema"
	"github.com/spf13/cobra"
	"github.com/tmc/langchaingo/chains"
	"github.com/tmc/langchaingo/llms"
)

var (
	// å…¨å±€é…ç½®
	outputDir  string
	outputFile string
	verbose    bool
	
	// éªŒè¯é…ç½®
	enableAPITest bool  // æ˜¯å¦å¯ç”¨çœŸå®APIè°ƒç”¨æµ‹è¯•

	// LLMé…ç½®
	llmType     string
	model       string
	temperature float64
	maxTokens   int
	baseURL     string

	// Chainé…ç½®
	chainType      string
	memoryType     string
	promptTemplate string

	// Agenté…ç½®
	agentType string
	maxSteps  int

	// Executoré…ç½®
	maxIterations           int
	returnIntermediateSteps bool
)

var configGenCmd = &cobra.Command{
	Use:   "config-gen",
	Short: "ğŸš€ LangChainGo-CN é…ç½®æ–‡ä»¶ç”Ÿæˆå™¨",
	Long: `ğŸš€ LangChainGo-CN é…ç½®æ–‡ä»¶ç”Ÿæˆå™¨

ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿç”ŸæˆLangChainç»„ä»¶é…ç½®æ–‡ä»¶ã€‚
æ”¯æŒLLMã€Chainã€Agentã€Executorç­‰ç»„ä»¶çš„é…ç½®ç”Ÿæˆã€‚

æ”¯æŒçš„LLMç±»å‹:
  â€¢ deepseek    - DeepSeekæ¨¡å‹
  â€¢ kimi        - Kimiæœˆä¹‹æš—é¢æ¨¡å‹
  â€¢ openai      - OpenAI GPTæ¨¡å‹
  â€¢ qwen        - é€šä¹‰åƒé—®æ¨¡å‹
  â€¢ zhipu       - æ™ºè°±AI GLMæ¨¡å‹
  â€¢ siliconflow - ç¡…åŸºæµåŠ¨å¹³å°æ¨¡å‹
  â€¢ anthropic   - Anthropic Claudeæ¨¡å‹
  â€¢ ollama      - æœ¬åœ°Ollamaæ¨¡å‹`,
	Example: `  # ç”ŸæˆDeepSeekèŠå¤©é…ç½®
  langchaingo-cn config-gen preset deepseek-chat -o deepseek.json

  # ç”Ÿæˆè‡ªå®šä¹‰LLMé…ç½®
  langchaingo-cn config-gen llm --llm deepseek --model deepseek-chat -o my_llm.json

  # ç”ŸæˆChainé…ç½®
  langchaingo-cn config-gen chain --llm kimi --model moonshot-v1-8k --memory conversation_buffer

  # ç”ŸæˆAgenté…ç½®
  langchaingo-cn config-gen agent --llm openai --model gpt-4 --agent-type zero_shot_react`,
}

// LLMå‘½ä»¤
var llmCmd = &cobra.Command{
	Use:   "llm",
	Short: "ç”ŸæˆLLMé…ç½®æ–‡ä»¶",
	Long:  "ç”Ÿæˆå¤§è¯­è¨€æ¨¡å‹(LLM)çš„é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒDeepSeekã€Kimiã€OpenAIã€æ™ºè°±AIã€ç¡…åŸºæµåŠ¨ç­‰æ¨¡å‹",
	Example: `  # ç”ŸæˆDeepSeeké…ç½®
  config-gen llm --llm deepseek --model deepseek-chat

  # ç”Ÿæˆå¸¦å‚æ•°çš„OpenAIé…ç½®
  config-gen llm --llm openai --model gpt-4 --temperature 0.7 --max-tokens 2048`,
	Run: func(cmd *cobra.Command, args []string) {
		if llmType == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šLLMç±»å‹ (--llm)")
		}
		if model == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šæ¨¡å‹åç§° (--model)")
		}

		generator := schema.NewConfigGenerator(outputDir)
		template := schema.LLMTemplate{
			Type:  llmType,
			Model: model,
		}

		if temperature > 0 {
			template.Temperature = temperature
		}
		if maxTokens > 0 {
			template.MaxTokens = maxTokens
		}
		if baseURL != "" {
			template.BaseURL = baseURL
		}

		if err := generator.GenerateLLMConfig(template, outputFile); err != nil {
			log.Fatal("âŒ ç”ŸæˆLLMé…ç½®å¤±è´¥:", err)
		}

		printSuccess("LLMé…ç½®")
	},
}

// Chainå‘½ä»¤
var chainCmd = &cobra.Command{
	Use:   "chain",
	Short: "ç”ŸæˆChainé…ç½®æ–‡ä»¶",
	Long:  "ç”Ÿæˆé“¾(Chain)çš„é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒå¯¹è¯é“¾ã€LLMé“¾ç­‰ç±»å‹",
	Example: `  # ç”Ÿæˆå¯¹è¯é“¾é…ç½®
  config-gen chain --llm deepseek --model deepseek-chat --memory conversation_buffer

  # ç”Ÿæˆå¸¦è‡ªå®šä¹‰æç¤ºçš„é“¾é…ç½®
  config-gen chain --llm kimi --model moonshot-v1-8k --prompt "ä½ æ˜¯ä¸“ä¸šåŠ©æ‰‹ï¼š{{.input}}"`,
	Run: func(cmd *cobra.Command, args []string) {
		if llmType == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šLLMç±»å‹ (--llm)")
		}
		if model == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šæ¨¡å‹åç§° (--model)")
		}

		generator := schema.NewConfigGenerator(outputDir)
		template := schema.ChainTemplate{
			Type: getChainType(),
			LLMTemplate: schema.LLMTemplate{
				Type:        llmType,
				Model:       model,
				Temperature: temperature,
			},
		}

		if maxTokens > 0 {
			template.LLMTemplate.MaxTokens = maxTokens
		}
		if baseURL != "" {
			template.LLMTemplate.BaseURL = baseURL
		}
		if memoryType != "" {
			template.MemoryType = memoryType
		}
		if promptTemplate != "" {
			template.PromptTemplate = promptTemplate
			template.InputVariables = []string{"input"}
		}

		if err := generator.GenerateChainConfig(template, outputFile); err != nil {
			log.Fatal("âŒ ç”ŸæˆChainé…ç½®å¤±è´¥:", err)
		}

		printSuccess("Chainé…ç½®")
	},
}

// Agentå‘½ä»¤
var agentCmd = &cobra.Command{
	Use:   "agent",
	Short: "ç”ŸæˆAgenté…ç½®æ–‡ä»¶",
	Long:  "ç”Ÿæˆæ™ºèƒ½ä½“(Agent)çš„é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒé›¶æ ·æœ¬ReActã€å¯¹è¯ReActç­‰ç±»å‹",
	Example: `  # ç”Ÿæˆé›¶æ ·æœ¬ReActæ™ºèƒ½ä½“
  config-gen agent --llm openai --model gpt-4 --agent-type zero_shot_react

  # ç”Ÿæˆå¯¹è¯æ™ºèƒ½ä½“
  config-gen agent --llm deepseek --model deepseek-chat --agent-type conversational_react --max-steps 5`,
	Run: func(cmd *cobra.Command, args []string) {
		if llmType == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šLLMç±»å‹ (--llm)")
		}
		if model == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šæ¨¡å‹åç§° (--model)")
		}

		generator := schema.NewConfigGenerator(outputDir)
		template := schema.AgentTemplate{
			Type: getAgentType(),
			LLMTemplate: schema.LLMTemplate{
				Type:        llmType,
				Model:       model,
				Temperature: temperature,
			},
			MemoryType: memoryType,
			MaxSteps:   maxSteps,
		}

		if maxTokens > 0 {
			template.LLMTemplate.MaxTokens = maxTokens
		}
		if baseURL != "" {
			template.LLMTemplate.BaseURL = baseURL
		}

		if err := generator.GenerateAgentConfig(template, outputFile); err != nil {
			log.Fatal("âŒ ç”ŸæˆAgenté…ç½®å¤±è´¥:", err)
		}

		printSuccess("Agenté…ç½®")
	},
}

// Executorå‘½ä»¤
var executorCmd = &cobra.Command{
	Use:   "executor",
	Short: "ç”ŸæˆExecutoré…ç½®æ–‡ä»¶",
	Long:  "ç”Ÿæˆæ‰§è¡Œå™¨(Executor)çš„é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨æ–°çš„usageé£æ ¼é…ç½®",
	Example: `  # ç”ŸæˆåŸºæœ¬æ‰§è¡Œå™¨é…ç½®
  config-gen executor --llm deepseek --model deepseek-chat

  # ç”Ÿæˆå¸¦è¯¦ç»†å‚æ•°çš„æ‰§è¡Œå™¨é…ç½®
  config-gen executor --llm kimi --model moonshot-v1-8k --max-iterations 10 --return-steps`,
	Run: func(cmd *cobra.Command, args []string) {
		if llmType == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šLLMç±»å‹ (--llm)")
		}
		if model == "" {
			log.Fatal("âŒ è¯·æŒ‡å®šæ¨¡å‹åç§° (--model)")
		}

		generator := schema.NewConfigGenerator(outputDir)
		template := schema.ExecutorTemplate{
			AgentTemplate: schema.AgentTemplate{
				Type: getAgentType(),
				LLMTemplate: schema.LLMTemplate{
					Type:        llmType,
					Model:       model,
					Temperature: temperature,
				},
				MemoryType: memoryType,
				MaxSteps:   maxSteps,
			},
			MaxIterations:           maxIterations,
			ReturnIntermediateSteps: returnIntermediateSteps,
		}

		if maxTokens > 0 {
			template.AgentTemplate.LLMTemplate.MaxTokens = maxTokens
		}
		if baseURL != "" {
			template.AgentTemplate.LLMTemplate.BaseURL = baseURL
		}

		if err := generator.GenerateExecutorConfig(template, outputFile); err != nil {
			log.Fatal("âŒ ç”ŸæˆExecutoré…ç½®å¤±è´¥:", err)
		}

		printSuccess("Executoré…ç½®")
	},
}

// Presetå‘½ä»¤
var presetCmd = &cobra.Command{
	Use:       "preset [é…ç½®åç§°]",
	Short:     "ç”Ÿæˆé¢„è®¾é…ç½®æ–‡ä»¶",
	Long:      "ä½¿ç”¨é¢„å®šä¹‰çš„é…ç½®æ¨¡æ¿å¿«é€Ÿç”Ÿæˆå¸¸ç”¨é…ç½®æ–‡ä»¶",
	Args:      cobra.ExactArgs(1),
	ValidArgs: []string{"deepseek-chat", "kimi-chat", "openai-chat", "qwen-chat", "zhipu-chat", "siliconflow-chat", "deepseek-executor", "zhipu-executor", "siliconflow-executor"},
	Example: `  # ç”ŸæˆDeepSeekèŠå¤©é…ç½®
  config-gen preset deepseek-chat -o deepseek.json

  # ç”Ÿæˆæ™ºè°±AIèŠå¤©é…ç½®
  config-gen preset zhipu-chat -o zhipu.json

  # ç”Ÿæˆç¡…åŸºæµåŠ¨èŠå¤©é…ç½®
  config-gen preset siliconflow-chat -o siliconflow.json

  # ç”Ÿæˆæ™ºè°±AIæ‰§è¡Œå™¨é…ç½®
  config-gen preset zhipu-executor -o executor.json`,
	Run: func(cmd *cobra.Command, args []string) {
		preset := args[0]
		generator := schema.NewConfigGenerator(outputDir)

		if err := generatePreset(generator, preset, outputFile); err != nil {
			log.Fatal("âŒ ç”Ÿæˆé¢„è®¾é…ç½®å¤±è´¥:", err)
		}

		printSuccess(fmt.Sprintf("é¢„è®¾é…ç½® [%s]", preset))
	},
}

// Listå‘½ä»¤
var listCmd = &cobra.Command{
	Use:   "list",
	Short: "åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„é¢„è®¾é…ç½®å’Œæ”¯æŒçš„ç±»å‹",
	Long:  "æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„é¢„è®¾é…ç½®ã€æ”¯æŒçš„LLMç±»å‹ã€Chainç±»å‹ç­‰ä¿¡æ¯",
	Run: func(cmd *cobra.Command, args []string) {
		fmt.Println("ğŸ“‹ å¯ç”¨çš„é¢„è®¾é…ç½®:")
		fmt.Println("  â€¢ deepseek-chat       - DeepSeekèŠå¤©é…ç½®")
		fmt.Println("  â€¢ kimi-chat           - KimièŠå¤©é…ç½®")
		fmt.Println("  â€¢ openai-chat         - OpenAIèŠå¤©é…ç½®")
		fmt.Println("  â€¢ qwen-chat           - é€šä¹‰åƒé—®èŠå¤©é…ç½®")
		fmt.Println("  â€¢ zhipu-chat          - æ™ºè°±AIèŠå¤©é…ç½®")
		fmt.Println("  â€¢ siliconflow-chat    - ç¡…åŸºæµåŠ¨èŠå¤©é…ç½®")
		fmt.Println("  â€¢ deepseek-executor   - DeepSeekæ‰§è¡Œå™¨é…ç½®")
		fmt.Println("  â€¢ zhipu-executor      - æ™ºè°±AIæ‰§è¡Œå™¨é…ç½®")
		fmt.Println("  â€¢ siliconflow-executor - ç¡…åŸºæµåŠ¨æ‰§è¡Œå™¨é…ç½®")

		fmt.Println("\nğŸ¤– æ”¯æŒçš„LLMç±»å‹:")
		fmt.Println("  â€¢ deepseek    - DeepSeekæ¨¡å‹")
		fmt.Println("  â€¢ kimi        - Kimiæœˆä¹‹æš—é¢æ¨¡å‹")
		fmt.Println("  â€¢ openai      - OpenAI GPTæ¨¡å‹")
		fmt.Println("  â€¢ qwen        - é€šä¹‰åƒé—®æ¨¡å‹")
		fmt.Println("  â€¢ zhipu       - æ™ºè°±AI GLMæ¨¡å‹")
		fmt.Println("  â€¢ siliconflow - ç¡…åŸºæµåŠ¨å¹³å°æ¨¡å‹")
		fmt.Println("  â€¢ anthropic   - Anthropic Claudeæ¨¡å‹")
		fmt.Println("  â€¢ ollama      - æœ¬åœ°Ollamaæ¨¡å‹")

		fmt.Println("\nâ›“ï¸  æ”¯æŒçš„Chainç±»å‹:")
		fmt.Println("  â€¢ conversation - å¯¹è¯é“¾")
		fmt.Println("  â€¢ llm          - LLMé“¾")
		fmt.Println("  â€¢ sequential   - é¡ºåºé“¾")

		fmt.Println("\nğŸ¤– æ”¯æŒçš„Agentç±»å‹:")
		fmt.Println("  â€¢ zero_shot_react      - é›¶æ ·æœ¬ReActæ™ºèƒ½ä½“")
		fmt.Println("  â€¢ conversational_react - å¯¹è¯ReActæ™ºèƒ½ä½“")

		fmt.Println("\nğŸ’¾ æ”¯æŒçš„Memoryç±»å‹:")
		fmt.Println("  â€¢ conversation_buffer - ä¼šè¯ç¼“å†²è®°å¿†")
		fmt.Println("  â€¢ simple              - ç®€å•è®°å¿†")
	},
}

// Validateå‘½ä»¤
var validateCmd = &cobra.Command{
	Use:   "validate [config-file]",
	Short: "éªŒè¯å¹¶æµ‹è¯•JSONé…ç½®æ–‡ä»¶",
	Long: `éªŒè¯å¹¶æµ‹è¯•JSONé…ç½®æ–‡ä»¶æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ

è¯¥å‘½ä»¤ä¼š:
1. è§£æJSONé…ç½®æ–‡ä»¶
2. éªŒè¯é…ç½®è¯­æ³•å’Œç»“æ„
3. åˆ›å»ºç›¸å…³ç»„ä»¶å®ä¾‹ 
4. æ‰§è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•
5. å¯é€‰çš„çœŸå®APIè°ƒç”¨æµ‹è¯•
6. æŠ¥å‘ŠéªŒè¯ç»“æœ

éªŒè¯çº§åˆ«:
â€¢ åŸºç¡€éªŒè¯: æ£€æŸ¥é…ç½®è¯­æ³•å’Œç»„ä»¶åˆ›å»º
â€¢ APIæµ‹è¯•: å‘é€çœŸå®è¯·æ±‚æµ‹è¯•LLM/Chain/AgentåŠŸèƒ½

ç¤ºä¾‹:
  # åŸºç¡€éªŒè¯é…ç½®æ–‡ä»¶
  xin config-gen validate config.json
  
  # å®Œæ•´éªŒè¯(åŒ…å«çœŸå®APIè°ƒç”¨)
  xin config-gen validate config.json --api-test
  
  # éªŒè¯é…ç½®å¹¶æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
  xin config-gen validate config.json --verbose`,
	Args: cobra.ExactArgs(1),
	Run: func(cmd *cobra.Command, args []string) {
		configFile := args[0]
		validateConfiguration(configFile)
	},
}

func init() {
	// å…¨å±€æ ‡å¿—
	configGenCmd.PersistentFlags().StringVarP(&outputDir, "dir", "d", ".", "è¾“å‡ºç›®å½•")
	configGenCmd.PersistentFlags().StringVarP(&outputFile, "output", "o", "config.json", "è¾“å‡ºæ–‡ä»¶å")
	configGenCmd.PersistentFlags().BoolVarP(&verbose, "verbose", "v", false, "è¯¦ç»†è¾“å‡º")

	// LLMå‘½ä»¤æ ‡å¿—
	llmCmd.Flags().StringVar(&llmType, "llm", "", "LLMç±»å‹ (deepseek|kimi|openai|qwen|anthropic|ollama) [å¿…éœ€]")
	llmCmd.Flags().StringVar(&model, "model", "", "æ¨¡å‹åç§° [å¿…éœ€]")
	llmCmd.Flags().Float64Var(&temperature, "temperature", 0, "æ¸©åº¦å‚æ•° (0.0-2.0)")
	llmCmd.Flags().IntVar(&maxTokens, "max-tokens", 0, "æœ€å¤§tokenæ•°")
	llmCmd.Flags().StringVar(&baseURL, "base-url", "", "è‡ªå®šä¹‰APIåŸºç¡€URL")
	llmCmd.MarkFlagRequired("llm")
	llmCmd.MarkFlagRequired("model")

	// Chainå‘½ä»¤æ ‡å¿—
	chainCmd.Flags().StringVar(&llmType, "llm", "", "LLMç±»å‹ [å¿…éœ€]")
	chainCmd.Flags().StringVar(&model, "model", "", "æ¨¡å‹åç§° [å¿…éœ€]")
	chainCmd.Flags().StringVar(&chainType, "chain-type", "conversation", "Chainç±»å‹ (conversation|llm|sequential)")
	chainCmd.Flags().StringVar(&memoryType, "memory", "conversation_buffer", "Memoryç±»å‹ (conversation_buffer|simple)")
	chainCmd.Flags().StringVar(&promptTemplate, "prompt", "", "è‡ªå®šä¹‰æç¤ºæ¨¡æ¿")
	chainCmd.Flags().Float64Var(&temperature, "temperature", 0.7, "æ¸©åº¦å‚æ•°")
	chainCmd.Flags().IntVar(&maxTokens, "max-tokens", 0, "æœ€å¤§tokenæ•°")
	chainCmd.Flags().StringVar(&baseURL, "base-url", "", "è‡ªå®šä¹‰APIåŸºç¡€URL")
	chainCmd.MarkFlagRequired("llm")
	chainCmd.MarkFlagRequired("model")

	// Agentå‘½ä»¤æ ‡å¿—
	agentCmd.Flags().StringVar(&llmType, "llm", "", "LLMç±»å‹ [å¿…éœ€]")
	agentCmd.Flags().StringVar(&model, "model", "", "æ¨¡å‹åç§° [å¿…éœ€]")
	agentCmd.Flags().StringVar(&agentType, "agent-type", "zero_shot_react", "Agentç±»å‹ (zero_shot_react|conversational_react)")
	agentCmd.Flags().StringVar(&memoryType, "memory", "conversation_buffer", "Memoryç±»å‹")
	agentCmd.Flags().IntVar(&maxSteps, "max-steps", 5, "æœ€å¤§æ­¥æ•°")
	agentCmd.Flags().Float64Var(&temperature, "temperature", 0.3, "æ¸©åº¦å‚æ•°")
	agentCmd.Flags().IntVar(&maxTokens, "max-tokens", 0, "æœ€å¤§tokenæ•°")
	agentCmd.Flags().StringVar(&baseURL, "base-url", "", "è‡ªå®šä¹‰APIåŸºç¡€URL")
	agentCmd.MarkFlagRequired("llm")
	agentCmd.MarkFlagRequired("model")

	// Executorå‘½ä»¤æ ‡å¿—
	executorCmd.Flags().StringVar(&llmType, "llm", "", "LLMç±»å‹ [å¿…éœ€]")
	executorCmd.Flags().StringVar(&model, "model", "", "æ¨¡å‹åç§° [å¿…éœ€]")
	executorCmd.Flags().StringVar(&agentType, "agent-type", "zero_shot_react", "Agentç±»å‹")
	executorCmd.Flags().StringVar(&memoryType, "memory", "conversation_buffer", "Memoryç±»å‹")
	executorCmd.Flags().IntVar(&maxSteps, "max-steps", 5, "æœ€å¤§æ­¥æ•°")
	executorCmd.Flags().IntVar(&maxIterations, "max-iterations", 10, "æœ€å¤§è¿­ä»£æ¬¡æ•°")
	executorCmd.Flags().BoolVar(&returnIntermediateSteps, "return-steps", false, "è¿”å›ä¸­é—´æ­¥éª¤")
	executorCmd.Flags().Float64Var(&temperature, "temperature", 0.7, "æ¸©åº¦å‚æ•°")
	executorCmd.Flags().IntVar(&maxTokens, "max-tokens", 0, "æœ€å¤§tokenæ•°")
	executorCmd.Flags().StringVar(&baseURL, "base-url", "", "è‡ªå®šä¹‰APIåŸºç¡€URL")
	executorCmd.MarkFlagRequired("llm")
	executorCmd.MarkFlagRequired("model")

	// Validateå‘½ä»¤æ ‡å¿—
	validateCmd.Flags().BoolVarP(&enableAPITest, "api-test", "t", false, "å¯ç”¨çœŸå®APIè°ƒç”¨æµ‹è¯•")

	// æ·»åŠ å­å‘½ä»¤
	configGenCmd.AddCommand(llmCmd)
	configGenCmd.AddCommand(chainCmd)
	configGenCmd.AddCommand(agentCmd)
	configGenCmd.AddCommand(executorCmd)
	configGenCmd.AddCommand(presetCmd)
	configGenCmd.AddCommand(listCmd)
	configGenCmd.AddCommand(validateCmd)
}

// è¾…åŠ©å‡½æ•°
func getChainType() string {
	if chainType == "" {
		return "conversation"
	}
	return chainType
}

func getAgentType() string {
	if agentType == "" {
		return "zero_shot_react"
	}
	return agentType
}

func generatePreset(generator *schema.ConfigGenerator, preset, output string) error {
	switch strings.ToLower(preset) {
	case "deepseek-chat":
		return generator.GenerateDeepSeekChatConfig(output)
	case "kimi-chat":
		return generator.GenerateKimiChatConfig(output)
	case "openai-chat":
		return generator.GenerateOpenAIChatConfig(output)
	case "qwen-chat":
		return generator.GenerateQwenChatConfig(output)
	case "zhipu-chat":
		return generator.GenerateZhipuChatConfig(output)
	case "siliconflow-chat":
		return generator.GenerateSiliconFlowChatConfig(output)
	case "deepseek-executor":
		return generator.GenerateExecutorWithDeepSeek(output)
	case "zhipu-executor":
		return generator.GenerateExecutorWithZhipu(output)
	case "siliconflow-executor":
		return generator.GenerateExecutorWithSiliconFlow(output)
	default:
		return fmt.Errorf("ä¸æ”¯æŒçš„é¢„è®¾é…ç½®: %s", preset)
	}
}

func printSuccess(configType string) {
	if verbose {
		fmt.Printf("\nâœ¨ %sç”ŸæˆæˆåŠŸ!\n", configType)
		fmt.Printf("ğŸ“ æ–‡ä»¶ä½ç½®: %s/%s\n", outputDir, outputFile)
		fmt.Println("\nğŸ’¡ ä½¿ç”¨æŒ‡å—:")
		fmt.Println("   1. ğŸ”‘ è®¾ç½®ç›¸åº”çš„ç¯å¢ƒå˜é‡ (å¦‚ DEEPSEEK_API_KEY)")
		fmt.Println("   2. ğŸ“ ä½¿ç”¨ schema.CreateApplicationFromFile() åŠ è½½é…ç½®")
		fmt.Println("   3. ğŸš€ å¼€å§‹ä½¿ç”¨æ‚¨çš„AIåº”ç”¨!")
	} else {
		fmt.Printf("âœ… %så·²ç”Ÿæˆ: %s/%s\n", configType, outputDir, outputFile)
	}
}

// validateConfiguration éªŒè¯é…ç½®æ–‡ä»¶
func validateConfiguration(configFile string) {
	fmt.Printf("ğŸ” éªŒè¯é…ç½®æ–‡ä»¶: %s\n", configFile)

	// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
	if _, err := os.Stat(configFile); os.IsNotExist(err) {
		fmt.Printf("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: %s\n", configFile)
		return
	}

	if verbose {
		fmt.Println("\nğŸ“‹ éªŒè¯æ­¥éª¤:")
		fmt.Println("   1. ğŸ“„ è§£æJSONé…ç½®æ–‡ä»¶...")
	}

	// æ­¥éª¤1: è§£æé…ç½®æ–‡ä»¶
	app, err := schema.CreateApplicationFromFile(configFile)
	if err != nil {
		fmt.Printf("âŒ é…ç½®æ–‡ä»¶è§£æå¤±è´¥: %v\n", err)
		return
	}

	if verbose {
		fmt.Println("   âœ… JSONé…ç½®è§£ææˆåŠŸ")
		fmt.Println("   2. ğŸ”§ éªŒè¯ç»„ä»¶åˆ›å»º...")
	}

	// ç»Ÿè®¡åˆ›å»ºçš„ç»„ä»¶
	var stats struct {
		llms     int
		memories int
		chains   int
		agents   int
	}

	// éªŒè¯LLMç»„ä»¶
	for name, llm := range app.LLMs {
		if llm == nil {
			fmt.Printf("âŒ LLMç»„ä»¶åˆ›å»ºå¤±è´¥: %s\n", name)
			return
		}
		stats.llms++
		if verbose {
			fmt.Printf("      âœ… LLM: %s\n", name)
		}
	}

	// éªŒè¯Memoryç»„ä»¶
	for name, memory := range app.Memories {
		if memory == nil {
			fmt.Printf("âŒ Memoryç»„ä»¶åˆ›å»ºå¤±è´¥: %s\n", name)
			return
		}
		stats.memories++
		if verbose {
			fmt.Printf("      âœ… Memory: %s\n", name)
		}
	}

	// éªŒè¯Chainç»„ä»¶
	for name, chain := range app.Chains {
		if chain == nil {
			fmt.Printf("âŒ Chainç»„ä»¶åˆ›å»ºå¤±è´¥: %s\n", name)
			return
		}
		stats.chains++
		if verbose {
			fmt.Printf("      âœ… Chain: %s\n", name)
		}
	}

	// éªŒè¯Agentç»„ä»¶
	for name, agent := range app.Agents {
		if agent == nil {
			fmt.Printf("âŒ Agentç»„ä»¶åˆ›å»ºå¤±è´¥: %s\n", name)
			return
		}
		stats.agents++
		if verbose {
			fmt.Printf("      âœ… Agent: %s\n", name)
		}
	}

	// æ³¨æ„: Agentså­—æ®µå®é™…ä¸ŠåŒ…å«çš„æ˜¯ agents.Executor
	// è¿™é‡Œä¸éœ€è¦å•ç‹¬éªŒè¯Executorsï¼Œå› ä¸ºå®ƒä»¬åŒ…å«åœ¨Agentsä¸­

	if verbose {
		fmt.Println("   3. ğŸ§ª æ‰§è¡ŒåŠŸèƒ½æµ‹è¯•...")
	}

	// æ­¥éª¤3: åŸºæœ¬åŠŸèƒ½æµ‹è¯•
	testSuccess := true

	// æµ‹è¯•GetModelsæ–¹æ³•
	for name, llm := range app.LLMs {
		if modelsGetter, ok := llm.(interface{ GetModels() []string }); ok {
			models := modelsGetter.GetModels()
			if len(models) == 0 {
				fmt.Printf("âš ï¸  LLM %s çš„ GetModels() è¿”å›ç©ºæ¨¡å‹åˆ—è¡¨\n", name)
			} else if verbose {
				fmt.Printf("      âœ… LLM %s æ”¯æŒ %d ä¸ªæ¨¡å‹\n", name, len(models))
			}
		}
	}

	// å¦‚æœå¯ç”¨APIæµ‹è¯•ï¼Œè¿›è¡ŒçœŸå®è°ƒç”¨æµ‹è¯•
	if enableAPITest {
		if verbose {
			fmt.Println("      ğŸŒ æ‰§è¡ŒçœŸå®APIè°ƒç”¨æµ‹è¯•...")
		} else {
			fmt.Println("   ğŸŒ æ‰§è¡ŒçœŸå®APIè°ƒç”¨æµ‹è¯•...")
		}
		
		// æµ‹è¯•LLMçœŸå®APIè°ƒç”¨
		for name, llm := range app.LLMs {
			if verbose {
				fmt.Printf("      ğŸ” æµ‹è¯•LLM %s çš„APIè°ƒç”¨...\n", name)
			}
			
			if !testLLMAPICall(name, llm, verbose) {
				testSuccess = false
			}
		}

		// æµ‹è¯•Chainçš„çœŸå®è°ƒç”¨
		for name, chain := range app.Chains {
			if verbose {
				fmt.Printf("      ğŸ” æµ‹è¯•Chain %s çš„å¯¹è¯åŠŸèƒ½...\n", name)
			}
			
			if !testChainAPICall(name, chain, verbose) {
				testSuccess = false
			}
		}

		// æµ‹è¯•Agentçš„çœŸå®è°ƒç”¨
		for name, agent := range app.Agents {
			if verbose {
				fmt.Printf("      ğŸ” æµ‹è¯•Agent %s çš„æ‰§è¡ŒåŠŸèƒ½...\n", name)
			}
			
			if !testAgentAPICall(name, agent, verbose) {
				testSuccess = false
			}
		}
	} else {
		if verbose {
			fmt.Println("      â„¹ï¸  è·³è¿‡APIè°ƒç”¨æµ‹è¯• (ä½¿ç”¨ --api-test å¯ç”¨)")
		}
		// å¦‚æœæœ‰ç»„ä»¶ï¼Œç»™å‡ºæç¤º
		if len(app.Chains) > 0 && verbose {
			fmt.Println("      â„¹ï¸  Chainç»„ä»¶å·²å°±ç»ªï¼Œå¯ç”¨äºå¯¹è¯æµ‹è¯•")
		}
	}

	// æ­¥éª¤4: ç”ŸæˆéªŒè¯æŠ¥å‘Š
	if verbose {
		fmt.Println("   4. ğŸ“Š ç”ŸæˆéªŒè¯æŠ¥å‘Š...")
	}

	fmt.Printf("\nâœ… é…ç½®éªŒè¯æˆåŠŸ! %s\n", configFile)
	fmt.Printf("ğŸ“Š ç»„ä»¶ç»Ÿè®¡:\n")
	fmt.Printf("   ğŸ¤– LLMs: %d\n", stats.llms)
	fmt.Printf("   ğŸ’¾ Memories: %d\n", stats.memories)
	fmt.Printf("   â›“ï¸  Chains: %d\n", stats.chains)
	fmt.Printf("   ğŸ¤– Agents/Executors: %d\n", stats.agents)

	if testSuccess {
		fmt.Println("\nğŸ‰ æ‰€æœ‰ç»„ä»¶éªŒè¯é€šè¿‡ï¼Œé…ç½®æ–‡ä»¶å¯ä»¥æ­£å¸¸ä½¿ç”¨!")
	} else {
		fmt.Println("\nâš ï¸  éƒ¨åˆ†ç»„ä»¶éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥è®¾ç½®å’Œç½‘ç»œè¿æ¥")
	}

	if verbose {
		fmt.Println("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
		fmt.Println("   1. è®¾ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡(API Keys)")
		fmt.Println("   2. åœ¨ä»£ç ä¸­ä½¿ç”¨ schema.CreateApplicationFromFile() åŠ è½½é…ç½®")
		fmt.Println("   3. å¼€å§‹æ„å»ºä½ çš„AIåº”ç”¨!")
	}
}

// testLLMAPICall æµ‹è¯•LLMçš„çœŸå®APIè°ƒç”¨
func testLLMAPICall(name string, llm llms.Model, verbose bool) bool {
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	// æµ‹è¯•é—®é¢˜
	testPrompt := "ä½ æ˜¯ä»€ä¹ˆæ¨¡å‹ï¼Ÿè¯·ç®€çŸ­å›ç­”ã€‚"
	
	if verbose {
		fmt.Printf("        ğŸ“¤ å‘é€æµ‹è¯•é—®é¢˜: %s\n", testPrompt)
	}

	// å°è¯•è°ƒç”¨LLM
	response, err := llms.GenerateFromSinglePrompt(ctx, llm, testPrompt)
	if err != nil {
		fmt.Printf("        âŒ LLM %s APIè°ƒç”¨å¤±è´¥: %v\n", name, err)
		return false
	}

	if response == "" {
		fmt.Printf("        âŒ LLM %s è¿”å›ç©ºå“åº”\n", name)
		return false
	}

	if verbose {
		// æˆªæ–­é•¿å“åº”
		truncatedResponse := response
		if len(response) > 100 {
			truncatedResponse = response[:100] + "..."
		}
		fmt.Printf("        ğŸ“¥ æ”¶åˆ°å“åº”: %s\n", truncatedResponse)
	}
	
	fmt.Printf("        âœ… LLM %s APIè°ƒç”¨æˆåŠŸ\n", name)
	return true
}

// testChainAPICall æµ‹è¯•Chainçš„çœŸå®è°ƒç”¨
func testChainAPICall(name string, chain chains.Chain, verbose bool) bool {
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	// æµ‹è¯•è¾“å…¥
	testInput := map[string]any{
		"input": "ä½ å¥½ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ æ˜¯ä»€ä¹ˆAIåŠ©æ‰‹ï¼Ÿ",
	}
	
	if verbose {
		fmt.Printf("        ğŸ“¤ å‘é€æµ‹è¯•è¾“å…¥: %s\n", testInput["input"])
	}

	// å°è¯•è°ƒç”¨Chain
	result, err := chains.Call(ctx, chain, testInput)
	if err != nil {
		fmt.Printf("        âŒ Chain %s è°ƒç”¨å¤±è´¥: %v\n", name, err)
		return false
	}

	// æ£€æŸ¥ç»“æœ
	if result == nil {
		fmt.Printf("        âŒ Chain %s è¿”å›ç©ºç»“æœ\n", name)
		return false
	}

	// å°è¯•è·å–è¾“å‡º
	var output string
	if outputValue, exists := result["output"]; exists {
		if str, ok := outputValue.(string); ok {
			output = str
		}
	} else if textValue, exists := result["text"]; exists {
		if str, ok := textValue.(string); ok {
			output = str
		}
	}

	if output == "" {
		fmt.Printf("        âŒ Chain %s æ²¡æœ‰äº§ç”Ÿæœ‰æ•ˆè¾“å‡º\n", name)
		return false
	}

	if verbose {
		// æˆªæ–­é•¿å“åº”
		truncatedOutput := output
		if len(output) > 100 {
			truncatedOutput = output[:100] + "..."
		}
		fmt.Printf("        ğŸ“¥ æ”¶åˆ°å“åº”: %s\n", truncatedOutput)
	}

	fmt.Printf("        âœ… Chain %s è°ƒç”¨æˆåŠŸ\n", name)
	return true
}

// testAgentAPICall æµ‹è¯•Agentçš„çœŸå®æ‰§è¡Œ
func testAgentAPICall(name string, agent interface{}, verbose bool) bool {
	ctx, cancel := context.WithTimeout(context.Background(), 45*time.Second)
	defer cancel()

	// æµ‹è¯•é—®é¢˜
	testInput := "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±çš„èƒ½åŠ›"
	
	if verbose {
		fmt.Printf("        ğŸ“¤ å‘é€æµ‹è¯•é—®é¢˜: %s\n", testInput)
	}

	// å°è¯•æ‰§è¡ŒAgent (agents.Executoræœ‰Callæ–¹æ³•)
	if executor, ok := agent.(interface {
		Call(ctx context.Context, inputs map[string]any) (map[string]any, error)
	}); ok {
		result, err := executor.Call(ctx, map[string]any{
			"input": testInput,
		})
		
		if err != nil {
			fmt.Printf("        âŒ Agent %s æ‰§è¡Œå¤±è´¥: %v\n", name, err)
			return false
		}

		// æ£€æŸ¥ç»“æœ
		if result == nil {
			fmt.Printf("        âŒ Agent %s è¿”å›ç©ºç»“æœ\n", name)
			return false
		}

		// å°è¯•è·å–è¾“å‡º
		var output string
		if outputValue, exists := result["output"]; exists {
			if str, ok := outputValue.(string); ok {
				output = str
			}
		}

		if output == "" {
			fmt.Printf("        âŒ Agent %s æ²¡æœ‰äº§ç”Ÿæœ‰æ•ˆè¾“å‡º\n", name)
			return false
		}

		if verbose {
			// æˆªæ–­é•¿å“åº”
			truncatedOutput := output
			if len(output) > 100 {
				truncatedOutput = output[:100] + "..."
			}
			fmt.Printf("        ğŸ“¥ æ”¶åˆ°å“åº”: %s\n", truncatedOutput)
		}

		fmt.Printf("        âœ… Agent %s æ‰§è¡ŒæˆåŠŸ\n", name)
		return true
	}

	fmt.Printf("        âš ï¸  Agent %s ä¸æ”¯æŒæ ‡å‡†è°ƒç”¨æ¥å£\n", name)
	return true // ä¸ç®—ä½œå¤±è´¥
}
